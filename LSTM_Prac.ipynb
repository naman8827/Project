{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Prac",
      "provenance": [],
      "authorship_tag": "ABX9TyOLzFzHSf7EI2UFtnolUNbX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naman8827/Project/blob/master/LSTM_Prac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIvpW6boL_n1",
        "colab_type": "code",
        "outputId": "d6774ef8-0278-4349-8b8b-90bf21bd6e12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "sentences = []\n",
        "s1 = 'this is sentence 1'\n",
        "s2 = 'this is sentence 2'\n",
        "\n",
        "sentences.append(s1)\n",
        "sentences.append(s2)\n",
        "\n",
        "def get_all_words(sentences) : \n",
        "\n",
        "  unf = [s.split(' ') for s in sentences]\n",
        "\n",
        "  all_words = []\n",
        "\n",
        "  for f in unf : \n",
        "    for f2 in f : \n",
        "      all_words.append(f2)\n",
        "\n",
        "  return all_words\n",
        "\n",
        "\n",
        "all_words = get_all_words(sentences)\n",
        "print(all_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this', 'is', 'sentence', '1', 'this', 'is', 'sentence', '2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q4AEEA6M1hm",
        "colab_type": "code",
        "outputId": "480fca51-c5df-49ff-b23a-042f70f2a16d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "def get_one_hot(s , s1 , all_words) : \n",
        "  flattened = []\n",
        "  one_hot_encoded_df = pd.get_dummies(list(set(all_words)))\n",
        "  print(one_hot_encoded_df)\n",
        "  print(np.array(one_hot_encoded_df['this']))\n",
        "  for a in [np.array(one_hot_encoded_df[s]) for s in s1.split(' ')] : \n",
        "    for aa in a : \n",
        "      flattened.append(aa)\n",
        "\n",
        "  \n",
        "get_one_hot(sentences , s1 , all_words)\n",
        "get_one_hot(sentences , s2 , all_words)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   1  2  is  sentence  this\n",
            "0  0  1   0         0     0\n",
            "1  0  0   0         1     0\n",
            "2  1  0   0         0     0\n",
            "3  0  0   1         0     0\n",
            "4  0  0   0         0     1\n",
            "[0 0 0 0 1]\n",
            "   1  2  is  sentence  this\n",
            "0  0  1   0         0     0\n",
            "1  0  0   0         1     0\n",
            "2  1  0   0         0     0\n",
            "3  0  0   1         0     0\n",
            "4  0  0   0         0     1\n",
            "[0 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXH2QFHFTfRs",
        "colab_type": "code",
        "outputId": "bfdf86a6-4429-4b4f-d413-5b9d31cf522a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "def vocab_creater(text_lists, VOCAB_SIZE):\n",
        "\n",
        "  tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "  tokenizer.fit_on_texts(text_lists)\n",
        "  dictionary = tokenizer.word_index\n",
        "  \n",
        "  word2idx = {}\n",
        "  idx2word = {}\n",
        "  for k, v in dictionary.items():\n",
        "      if v < VOCAB_SIZE:\n",
        "          word2idx[k] = v\n",
        "          idx2word[v] = k\n",
        "      if v >= VOCAB_SIZE-1:\n",
        "          continue\n",
        "          \n",
        "  return word2idx, idx2word\n",
        "\n",
        "encoder_input_text='this is a pen'\n",
        "word2idx, idx2word = vocab_creater(text_lists=encoder_input_text, VOCAB_SIZE=14999)\n",
        "print(word2idx, idx2word)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'i': 1, 's': 2, 't': 3, 'h': 4, 'a': 5, 'p': 6, 'e': 7, 'n': 8} {1: 'i', 2: 's', 3: 't', 4: 'h', 5: 'a', 6: 'p', 7: 'e', 8: 'n'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_zZC7mIZ1ZC",
        "colab_type": "code",
        "outputId": "6e15e222-6322-44d1-b071-8014d6f06ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "def seq2seq_model_builder(HIDDEN_DIM=300):\n",
        "    \n",
        "    encoder_inputs = Input(shape=(MAX_LEN, ), dtype='int32',)\n",
        "    encoder_embedding = embed_layer(encoder_inputs)\n",
        "    encoder_LSTM = LSTM(HIDDEN_DIM, return_state=True)\n",
        "    encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
        "    \n",
        "    decoder_inputs = Input(shape=(MAX_LEN, ), dtype='int32',)\n",
        "    decoder_embedding = embed_layer(decoder_inputs)\n",
        "    decoder_LSTM = LSTM(HIDDEN_DIM, return_state=True, return_sequences=True)\n",
        "    decoder_outputs, _, _ = decoder_LSTM(decoder_embedding, initial_state=[state_h, state_c])\n",
        "    \n",
        "    # dense_layer = Dense(VOCAB_SIZE, activation='softmax')\n",
        "    outputs = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))(decoder_outputs)\n",
        "    model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "    \n",
        "    return model\n",
        "MAX_LEN=10   \n",
        "model = seq2seq_model_builder(HIDDEN_DIM=300)\n",
        "model.summary()    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0d956da096a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mMAX_LEN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq2seq_model_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHIDDEN_DIM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-0d956da096a4>\u001b[0m in \u001b[0;36mseq2seq_model_builder\u001b[0;34m(HIDDEN_DIM)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mseq2seq_model_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHIDDEN_DIM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mencoder_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mencoder_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mencoder_LSTM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHIDDEN_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[1;32m    176\u001b[0m                              \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                              \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                              input_tensor=tensor)\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;31m# Return tensor including _keras_shape and _keras_history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Note that in this case train_output and test_output are the same pointer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'input'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_uid\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         raise RuntimeError(\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;34m'It looks like you are trying to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;34m'a version of multi-backend Keras that '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;34m'does not support TensorFlow 2.0. We recommend '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOyclmRhayYc",
        "colab_type": "code",
        "outputId": "e41cadea-8933-4b2d-df71-884a6daf6136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "from pandas import Series\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# define contrived series\n",
        "data = [10.1, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]\n",
        "series = Series(data)\n",
        "#print (series)\n",
        "# prepare data for normalization\n",
        "values = series.values\n",
        "print(values)\n",
        "values = values.reshape((len (values), 1))\n",
        "print(values)\n",
        "# train the normalization\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler = scaler.fit(values)\n",
        "print ( 'Min : %f, Max : %f' % (scaler.data_min_, scaler.data_max_))\n",
        "# normalize the dataset and print\n",
        "normalized = scaler.transform(values)\n",
        "print (normalized)\n",
        "# inverse transform and print\n",
        "inversed = scaler.inverse_transform(normalized)\n",
        "#print (inversed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 10.1  20.   30.   40.   50.   60.   70.   80.   90.  100. ]\n",
            "[[ 10.1]\n",
            " [ 20. ]\n",
            " [ 30. ]\n",
            " [ 40. ]\n",
            " [ 50. ]\n",
            " [ 60. ]\n",
            " [ 70. ]\n",
            " [ 80. ]\n",
            " [ 90. ]\n",
            " [100. ]]\n",
            "Min : 10.100000, Max : 100.000000\n",
            "[[0.        ]\n",
            " [0.11012236]\n",
            " [0.22135706]\n",
            " [0.33259177]\n",
            " [0.44382647]\n",
            " [0.55506118]\n",
            " [0.66629588]\n",
            " [0.77753059]\n",
            " [0.88876529]\n",
            " [1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpvywISZjUAt",
        "colab_type": "code",
        "outputId": "a8c8fa56-74b7-4f69-b84c-15116c8811d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(5, input_shape=(2,1)))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation( sigmoid ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fd5bbfc43a24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0msigmoid\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSzOLerLD2MY",
        "colab_type": "code",
        "outputId": "ee63d953-8b5e-4599-a0c9-6cf225b12eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "from numpy import array\n",
        "data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "data = data.reshape((1, 5, 2))\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.1 0.2]\n",
            "  [0.3 0.4]\n",
            "  [0.5 0.6]\n",
            "  [0.7 0.8]\n",
            "  [0.9 1. ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLb53CrRBvAk",
        "colab_type": "code",
        "outputId": "523fbec0-7a4f-44da-87a4-a71eca40557c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import random\n",
        "def generate_sequence(length, n_features):\n",
        " return [random.randint(0, n_features-1) for _ in range (length)]\n",
        "p=generate_sequence(10,5)\n",
        "print(p)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4, 2, 2, 2, 3, 0, 0, 3, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyVYGHNuH4ju",
        "colab_type": "code",
        "outputId": "8e7a68e3-6b0e-484c-8dca-44eb86b3bc3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# one hot encode sequence\n",
        "from numpy import array\n",
        "import pandas\n",
        "def one_hot_encode(sequence, n_features):\n",
        " encoding = list()\n",
        " for value in sequence:\n",
        "  vector = [0 for _ in range (n_features)]\n",
        "  vector[value] = 1\n",
        "  encoding.append(vector)\n",
        " return array(encoding)\n",
        "print(p) \n",
        "Y=one_hot_encode(p, 5) \n",
        "print(Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4, 2, 2, 2, 3, 0, 0, 3, 2, 2]\n",
            "[[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5-y622uLSsI",
        "colab_type": "code",
        "outputId": "f317322d-6b08-47c3-f004-6e4a660eb533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "from numpy import array\n",
        "X = Y.reshape(1, 25, 2)\n",
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0 0]\n",
            "  [0 0]\n",
            "  [1 0]\n",
            "  [0 1]\n",
            "  [0 0]\n",
            "  [0 0]\n",
            "  [1 0]\n",
            "  [0 0]\n",
            "  [0 1]\n",
            "  [0 0]\n",
            "  [0 0]\n",
            "  [0 1]\n",
            "  [0 1]\n",
            "  [0 0]\n",
            "  [0 0]\n",
            "  [1 0]\n",
            "  [0 0]\n",
            "  [0 0]\n",
            "  [0 0]\n",
            "  [1 0]\n",
            "  [0 0]\n",
            "  [1 0]\n",
            "  [0 0]\n",
            "  [0 1]\n",
            "  [0 0]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1IcjZooYjqc",
        "colab_type": "code",
        "outputId": "4f06f573-b8fb-4bda-e53c-876a6081e8bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "# define model\n",
        "import numpy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Embedding, Activation\n",
        "out_index = 2\n",
        "model = Sequential()\n",
        "model.add(LSTM(25, input_shape=(length, n_features)))\n",
        "model.add(Dense(n_features, activation= 'softmax' ))\n",
        "model.compile (loss= 'categorical_crossentropy' , optimizer= 'adam' , metrics=[ 'acc' ])\n",
        "print (model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_6 (LSTM)                (None, 25)                3600      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                260       \n",
            "=================================================================\n",
            "Total params: 3,860\n",
            "Trainable params: 3,860\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0v4Nq-yrgNjb",
        "colab": {}
      },
      "source": [
        "#final\n",
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "import pandas\n",
        "# generate a sequence of random numbers in [0, n_features)\n",
        "def generate_sequence(length, n_features):\n",
        " return [randint(0, n_features-1) for _ in range (length)]\n",
        "# one hot encode sequence\n",
        "def one_hot_encode(sequence, n_features):\n",
        " encoding = list()\n",
        " for value in sequence:\n",
        "  vector = [0 for _ in range (n_features)]\n",
        "  vector[value] = 1\n",
        "  encoding.append(vector)\n",
        " return array(encoding)\n",
        "# decode a one hot encoded string\n",
        "def one_hot_decode(encoded_seq):\n",
        "  return [argmax(vector) for vector in encoded_seq]\n",
        "# generate one example for an lstm\n",
        "def generate_example(length, n_features, out_index):\n",
        "# generate sequence\n",
        " sequence = generate_sequence(length, n_features)\n",
        "# one hot encode\n",
        " encoded = one_hot_encode(sequence, n_features)\n",
        "# reshape sequence to be 3D\n",
        " X = encoded.reshape((1, length, n_features))\n",
        "# select output\n",
        " y = encoded[out_index].reshape(1, n_features)\n",
        " return X, y\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITZ9VSP46fZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnd7B7mFdu0B",
        "colab_type": "code",
        "outputId": "b7042956-c13b-4fe0-870b-76eb149e9fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fit model\n",
        "length = 5\n",
        "n_features = 10\n",
        "out_index = 2\n",
        "for i in range (100):\n",
        " X, y = generate_example(length, n_features, out_index)\n",
        " model.fit(X, y, epochs=1, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 - 0s - loss: 0.4843 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.1865 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.4395 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.3157 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.4448 - acc: 1.0000\n",
            "1/1 - 0s - loss: 2.0944 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.1264 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.3204 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.0745 - acc: 1.0000\n",
            "1/1 - 0s - loss: 2.4756 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.5454 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.9614 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.1040 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.4820 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.7002 - acc: 1.0000\n",
            "1/1 - 0s - loss: 2.5909 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.2996 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.2235 - acc: 1.0000\n",
            "1/1 - 0s - loss: 2.2132 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.6803 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.9085 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.7533 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.1798 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.4741 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.1027 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.9683 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.3444 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.2415 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.3929 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.6558 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.5233 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.0957 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.5739 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.2542 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.7046 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.7638 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.8789 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.6956 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.1767 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.6327 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.2008 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.9367 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.5344 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.3035 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.6098 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.8726 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.6145 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.5325 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.7721 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.4451 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.9392 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.1988 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.3819 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.0790 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.1864 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.0943 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.5643 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.2145 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.7962 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.2275 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.1150 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.1951 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 2.4819 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 3.2052 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.5982 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.8972 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.8225 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.6964 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.7252 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.4428 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.6821 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.9169 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.1224 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.8794 - acc: 1.0000\n",
            "1/1 - 0s - loss: 2.4068 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.2309 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.0904 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.4209 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.9658 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.4554 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.2569 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.5490 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.9881 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.2236 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.5916 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.4768 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.9106 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.7829 - acc: 1.0000\n",
            "1/1 - 0s - loss: 2.0513 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.8040 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.0866 - acc: 1.0000\n",
            "1/1 - 0s - loss: 2.7331 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.8199 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.0651 - acc: 1.0000\n",
            "1/1 - 0s - loss: 2.8266 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.3544 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 1.0597 - acc: 1.0000\n",
            "1/1 - 0s - loss: 0.1907 - acc: 1.0000\n",
            "1/1 - 0s - loss: 1.0415 - acc: 0.0000e+00\n",
            "1/1 - 0s - loss: 0.3339 - acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsXdCERy75Dy",
        "colab_type": "code",
        "outputId": "d5d7c49d-7299-41ee-b9f1-075d257b0f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# evaluate model\n",
        "correct = 0\n",
        "for i in range (100):\n",
        " X, y = generate_example(length, n_features, out_index)\n",
        " yhat = model.predict(X)\n",
        " if one_hot_decode(yhat) == one_hot_decode(y):\n",
        "  correct += 1\n",
        "print ( 'Accuracy: %f' % ((correct/100)*100.0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 72.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLX5AIgT8ZkE",
        "colab_type": "code",
        "outputId": "046e6789-ef2b-4034-a741-be1a61dca2e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "X, y = generate_example(length, n_features, out_index)\n",
        "yhat = model.predict(X)\n",
        "print ( 'Sequence: %s' % [one_hot_decode(x) for x in X])\n",
        "print ( 'Expected: %s' % one_hot_decode(y))\n",
        "print ( 'Predicted : %s' % one_hot_decode(yhat))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 64\n",
            "Sequence: [[6, 6, 7, 7, 9]]\n",
            "Expected: [7]\n",
            "Predicted : [7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVME1QMVE5j1",
        "colab_type": "code",
        "outputId": "dee42ecc-fe49-4745-effa-56a9426ee89c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Embedding, Activation\n",
        "model = Sequential()\n",
        "model.add(LSTM(1, input_shape=(3,1)))\n",
        "model.compile (optimizer= 'adam' , loss= 'mse' )\n",
        "# input time steps\n",
        "data = array([0.1, 0.2, 0.3]).reshape((1,3,1))\n",
        "print(data)\n",
        "# make and show prediction\n",
        "print (model.predict(data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.1]\n",
            "  [0.2]\n",
            "  [0.3]]]\n",
            "[[0.00433646]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv3rGcDFK33Y",
        "colab_type": "code",
        "outputId": "014a9eed-4a1f-465b-bef4-724adc82b24b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "# Example of one output for each input time step\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Embedding, Activation\n",
        "# define model where LSTM is also output layer\n",
        "model = Sequential()\n",
        "model.add(LSTM(1, return_sequences=True, input_shape=(3,1)))\n",
        "model.compile (optimizer= 'adam' , loss= 'mse' )\n",
        "# input time steps\n",
        "data = array([0.1, 0.2, 0.3]).reshape((1,3,1))\n",
        "print(data)\n",
        "# make and show prediction\n",
        "print (model.predict(data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.1]\n",
            "  [0.2]\n",
            "  [0.3]]]\n",
            "[[[-0.00613188]\n",
            "  [-0.01569991]\n",
            "  [-0.02686818]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok2PoVaQj8U6",
        "colab_type": "code",
        "outputId": "9edbdefd-6611-41fc-da7b-818c963f66a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from math import sin\n",
        "from math import pi\n",
        "from matplotlib import pyplot\n",
        "# create sequence\n",
        "length = 100\n",
        "freq = 5\n",
        "sequence = [sin(2 * pi * freq * (i/length)) for i in range (length)]\n",
        "# plot sequence\n",
        "pyplot.plot(sequence)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naHACRRAQEBDQ4Pz/ID+iwtgZXMUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL3SGv_AlaoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import seed\n",
        "from random import randint\n",
        "# generate lists of random integers and their sum\n",
        "def random_sum_pairs(n_examples, n_numbers, largest):\n",
        " X, y = list(), list()\n",
        " for i in range (n_examples):\n",
        "  in_pattern = [randint(1,largest) for _ in range (n_numbers)]\n",
        "  print(in_pattern)\n",
        "  out_pattern = sum (in_pattern)\n",
        "  print(out_pattern)\n",
        "  X.append(in_pattern)\n",
        "  y.append(out_pattern)\n",
        " return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaReiw_xlj3T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "4dc2afdc-5fa1-4ec3-c323-b4ddd80f307d"
      },
      "source": [
        "seed(1)\n",
        "n_samples = 2\n",
        "n_numbers = 2\n",
        "largest = 10\n",
        "# generate pairs\n",
        "X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
        "print (X, y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 10]\n",
            "13\n",
            "[2, 5]\n",
            "7\n",
            "[[3, 10], [2, 5]] [13, 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u_J8kXvO7pU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}